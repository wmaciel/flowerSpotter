{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CNN in Keras with Real-Time Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images into a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 128, 128, 3)\n",
      "(1360,)\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'square_images128'\n",
    "image_width = 128\n",
    "image_height = 128\n",
    "\n",
    "classes = ['daffodil',  'snowdrop', 'lily_valley', 'bluebell', 'crocus', 'iris', \n",
    "           'tigerlily', 'tulip', 'fritillary', 'sunflower', 'daisy', 'colts_foot', \n",
    "           'dandelion', 'cowslip', 'buttercup', 'windflower', 'pansy']\n",
    "\n",
    "class_dict = { class_name: index for (index, class_name) in enumerate(classes)}\n",
    "\n",
    "EXTENSIONS = [\".jpg\", \".bmp\", \".png\", \".pgm\", \".tif\", \".tiff\"]\n",
    "\n",
    "folders = os.listdir(base_dir)\n",
    "folders = [folder for folder in folders if folder != '.DS_Store']\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for folder_name in folders:\n",
    "    # We look up the class number based on the name of the folder the image is in.\n",
    "    # This maps a folder name like 'daffodil' to a class number like 0.\n",
    "    class_index = class_dict[folder_name]\n",
    "    \n",
    "    file_names = os.listdir(base_dir + '/' + folder_name)\n",
    "    #file_names = [name for name in file_names if name != '.DS_Store']\n",
    "    file_names = [name for name in file_names if os.path.splitext(name)[-1].lower() in EXTENSIONS]\n",
    "    \n",
    "    X = np.empty([len(file_names), image_width, image_height, 3])\n",
    "    y = []\n",
    "    \n",
    "    for (index, file_name) in enumerate(file_names):\n",
    "        file_path = base_dir + '/' + folder_name + '/' + file_name\n",
    "        #print(file_path)\n",
    "        I = np.array(Image.open(file_path))\n",
    "        X[index] = I\n",
    "        y.append(class_index)\n",
    "    \n",
    "    X_combined = X\n",
    "    y_array = np.array(y)\n",
    "    xs.append(X_combined)\n",
    "    ys.append(y_array)\n",
    "    \n",
    "    \n",
    "X_all = np.concatenate(xs)\n",
    "y_all = np.concatenate(ys)\n",
    "\n",
    "print(X_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle the input images and labels (IN THE SAME RANDOM ORDER SO THEY ARE STILL CORRELATED)\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(X_all)\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 20% of training data reserved for the validation set\\n# Here we're using a fixed validation set, not doing cross-validation\\npercentage_validation = 0.20\\n\\nnum_total = X_train.shape[0]\\nnum_validation = int(num_total * percentage_validation)\\nnum_training = num_total - num_validation\\n\\n# Our validation set will be num_validation points from the original training set.\\nmask = range(num_training, num_training + num_validation)\\nX_val = X_train[mask]\\ny_val = y_train[mask]\\n\\n# Our training set will be the first num_training points from the original training set.\\nmask = range(num_training)\\nX_train = X_train[mask]\\ny_train = y_train[mask]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training/validation/testing segments\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25)\n",
    "\n",
    "\"\"\"\n",
    "# 20% of training data reserved for the validation set\n",
    "# Here we're using a fixed validation set, not doing cross-validation\n",
    "percentage_validation = 0.20\n",
    "\n",
    "num_total = X_train.shape[0]\n",
    "num_validation = int(num_total * percentage_validation)\n",
    "num_training = num_total - num_validation\n",
    "\n",
    "# Our validation set will be num_validation points from the original training set.\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "\n",
    "# Our training set will be the first num_training points from the original training set.\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 3, 128, 128)\n",
      "(340, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data: subtract the mean image\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "#X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "\n",
    "# Transpose so that channels come first\n",
    "X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "#X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
    "X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "print(X_train.shape)\n",
    "#print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1020, 3, 128, 128)\n",
      "1020 train samples\n",
      "340 test samples\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Using real time data augmentation\n",
      "----------------------------------------\n",
      "Epoch 0\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 3.5735    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 2.8363    \n",
      "----------------------------------------\n",
      "Epoch 1\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 2.8362    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 2.8388    \n",
      "----------------------------------------\n",
      "Epoch 2\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 2.7172    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 3.7299    \n",
      "----------------------------------------\n",
      "Epoch 3\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 2.5282    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 2.1551    \n",
      "----------------------------------------\n",
      "Epoch 4\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 2.2049    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.9401    \n",
      "----------------------------------------\n",
      "Epoch 5\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.8872    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.7488    \n",
      "----------------------------------------\n",
      "Epoch 6\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.7460    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.6577    \n",
      "----------------------------------------\n",
      "Epoch 7\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 1.6374    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.5276    \n",
      "----------------------------------------\n",
      "Epoch 8\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.4756    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.5195    \n",
      "----------------------------------------\n",
      "Epoch 9\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 44s - train loss: 1.4415    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.3636    \n",
      "----------------------------------------\n",
      "Epoch 10\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 1.3012    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.4947    \n",
      "----------------------------------------\n",
      "Epoch 11\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.2969    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.5698    \n",
      "----------------------------------------\n",
      "Epoch 12\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.2764    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.3885    \n",
      "----------------------------------------\n",
      "Epoch 13\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 1.1402    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.4046    \n",
      "----------------------------------------\n",
      "Epoch 14\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 1.1089    \n",
      "Testing...\n",
      "340/340 [==============================] - 12s - test loss: 1.3373    \n",
      "----------------------------------------\n",
      "Epoch 15\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.0446    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.7338    \n",
      "----------------------------------------\n",
      "Epoch 16\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 1.0422    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.1642    \n",
      "----------------------------------------\n",
      "Epoch 17\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 1.0099    \n",
      "Testing...\n",
      "340/340 [==============================] - 12s - test loss: 1.5033    \n",
      "----------------------------------------\n",
      "Epoch 18\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 0.9442    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.2728    \n",
      "----------------------------------------\n",
      "Epoch 19\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 0.9136    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.1569    \n",
      "----------------------------------------\n",
      "Epoch 20\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 0.7756    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.2155    \n",
      "----------------------------------------\n",
      "Epoch 21\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 0.7761    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.3597    \n",
      "----------------------------------------\n",
      "Epoch 22\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 0.7548    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.3410    \n",
      "----------------------------------------\n",
      "Epoch 23\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 0.7717    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.0535    \n",
      "----------------------------------------\n",
      "Epoch 24\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 42s - train loss: 0.6266    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.2218    \n",
      "----------------------------------------\n",
      "Epoch 25\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 0.6237    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.1793    \n",
      "----------------------------------------\n",
      "Epoch 26\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 0.7079    \n",
      "Testing...\n",
      "340/340 [==============================] - 12s - test loss: 1.2684    \n",
      "----------------------------------------\n",
      "Epoch 27\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 0.5832    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.2521    \n",
      "----------------------------------------\n",
      "Epoch 28\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 0.5043    \n",
      "Testing...\n",
      "340/340 [==============================] - 11s - test loss: 1.3327    \n",
      "----------------------------------------\n",
      "Epoch 29\n",
      "----------------------------------------\n",
      "Training...\n",
      "1020/1020 [==============================] - 43s - train loss: 0.6137    \n",
      "Testing...\n",
      "340/340 [==============================] - 12s - test loss: 1.0031    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 770 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from six.moves import range\n",
    "\n",
    "'''\n",
    "    Train a (fairly simple) deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "    GPU run command:\n",
    "        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10_cnn.py\n",
    "\n",
    "    It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "    (it's still underfitting at that point, though).\n",
    "\n",
    "    Note: the data was pickled with Python 2, and some encoding issues might prevent you\n",
    "    from loading it in Python 3. You might have to load it in Python 2,\n",
    "    save it in a different format, load it in Python 3 and repickle it.\n",
    "'''\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 17\n",
    "num_epochs = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "# the images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(Y_train[0])\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='full',\n",
    "                        input_shape=(img_channels, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adadelta)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "print(\"Using real time data augmentation\")\n",
    "\n",
    "# this will do preprocessing and realtime data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print('-'*40)\n",
    "    print('Epoch', e)\n",
    "    print('-'*40)\n",
    "    print(\"Training...\")\n",
    "    # batch train with realtime data augmentation\n",
    "    progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "    for X_batch, Y_batch in datagen.flow(X_train, Y_train):\n",
    "        loss = model.train_on_batch(X_batch, Y_batch)\n",
    "        progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "\n",
    "    print(\"Testing...\")\n",
    "    # test time!\n",
    "    progbar = generic_utils.Progbar(X_test.shape[0])\n",
    "    for X_batch, Y_batch in datagen.flow(X_test, Y_test):\n",
    "        score = model.test_on_batch(X_batch, Y_batch)\n",
    "        progbar.add(X_batch.shape[0], values=[(\"test loss\", score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe36c6a7c90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlPTEW0QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3c819b610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_accuracies = history.history['acc']\n",
    "validation_accuracies = history.history['val_acc']\n",
    "\n",
    "plt.plot(training_accuracies)\n",
    "plt.plot(validation_accuracies)\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training a CNN on 128x128 Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
